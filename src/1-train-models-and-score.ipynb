{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc677f4-babd-4766-947e-c50e4aac6399",
   "metadata": {},
   "source": [
    "# Training 10 Models and Scoring\n",
    "## Load data in tidy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0899c1b2-b41d-4e80-925b-f99503ad9309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>rater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71120</th>\n",
       "      <td>2021000071.txt</td>\n",
       "      <td>To the Principal,\\r\\n\\r\\nI think that policy 1...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71121</th>\n",
       "      <td>2021000501.txt</td>\n",
       "      <td>Dear, TEACHER_NAME\\r\\n\\r\\nI think phone policy...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71122</th>\n",
       "      <td>2021000535.txt</td>\n",
       "      <td>Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71123</th>\n",
       "      <td>2021000667.txt</td>\n",
       "      <td>PHONES\\r\\n\\r\\nDear principal students should h...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71124</th>\n",
       "      <td>2021000683.txt</td>\n",
       "      <td>phones\\r\\n\\r\\ni think phones should be allowed...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                               text  \\\n",
       "71120  2021000071.txt  To the Principal,\\r\\n\\r\\nI think that policy 1...   \n",
       "71121  2021000501.txt  Dear, TEACHER_NAME\\r\\n\\r\\nI think phone policy...   \n",
       "71122  2021000535.txt  Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...   \n",
       "71123  2021000667.txt  PHONES\\r\\n\\r\\nDear principal students should h...   \n",
       "71124  2021000683.txt  phones\\r\\n\\r\\ni think phones should be allowed...   \n",
       "\n",
       "       labels    rater  \n",
       "71120     4.0  rater_1  \n",
       "71121     3.0  rater_1  \n",
       "71122     2.0  rater_1  \n",
       "71123     3.0  rater_1  \n",
       "71124     3.0  rater_1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/ellipse_raw_rater_scores_tidy.csv', index_col=0)\n",
    "df=df[df['variable']=='Phraseology']\n",
    "df = df[['Filename', 'Text', 'criterion', 'Rater']]\n",
    "df.columns = ['filename', 'text', 'labels', 'rater']\n",
    "unique_filenames = df['filename'].unique()\n",
    "df['labels']=df['labels'].astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602da229-b273-47f1-b424-1aa56af44042",
   "metadata": {},
   "source": [
    "## Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec5fa23-222a-4f68-92bd-5e3a5a52f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename Count per Rater:\n",
      "rater\n",
      "rater_1      860\n",
      "rater_10     782\n",
      "rater_11    1370\n",
      "rater_12    1222\n",
      "rater_13     890\n",
      "rater_14      31\n",
      "rater_15     991\n",
      "rater_16     447\n",
      "rater_17     119\n",
      "rater_18    1062\n",
      "rater_19    1043\n",
      "rater_2     1609\n",
      "rater_20      75\n",
      "rater_21     359\n",
      "rater_22     241\n",
      "rater_23     778\n",
      "rater_24     260\n",
      "rater_25      27\n",
      "rater_26     200\n",
      "rater_27     587\n",
      "rater_3      331\n",
      "rater_4      609\n",
      "rater_5      226\n",
      "rater_6     1340\n",
      "rater_7     1213\n",
      "rater_8      360\n",
      "rater_9      748\n",
      "Name: filename, dtype: int64\n",
      "\n",
      "Statistics:\n",
      "Mean: 658.5185185185185\n",
      "Standard Deviation: 461.8064338401776\n",
      "Minimum: 27\n",
      "Maximum: 1609\n"
     ]
    }
   ],
   "source": [
    "# Calculate filenames per rater\n",
    "filenames_per_rater = df.groupby('rater')['filename'].nunique()\n",
    "\n",
    "# Calculate statistics\n",
    "mean_filenames = filenames_per_rater.mean()\n",
    "std_filenames = filenames_per_rater.std()\n",
    "min_filenames = filenames_per_rater.min()\n",
    "max_filenames = filenames_per_rater.max()\n",
    "\n",
    "# Print results\n",
    "print(\"Filename Count per Rater:\")\n",
    "print(filenames_per_rater)\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"Mean: {mean_filenames}\")\n",
    "print(f\"Standard Deviation: {std_filenames}\")\n",
    "print(f\"Minimum: {min_filenames}\")\n",
    "print(f\"Maximum: {max_filenames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b036fc-1e0d-4be4-9663-a8f42c3444ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'text', 'labels', 'rater'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>rater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71120</th>\n",
       "      <td>2021000071.txt</td>\n",
       "      <td>To the Principal,\\r\\n\\r\\nI think that policy 1...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71121</th>\n",
       "      <td>2021000501.txt</td>\n",
       "      <td>Dear, TEACHER_NAME\\r\\n\\r\\nI think phone policy...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71122</th>\n",
       "      <td>2021000535.txt</td>\n",
       "      <td>Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71123</th>\n",
       "      <td>2021000667.txt</td>\n",
       "      <td>PHONES\\r\\n\\r\\nDear principal students should h...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71124</th>\n",
       "      <td>2021000683.txt</td>\n",
       "      <td>phones\\r\\n\\r\\ni think phones should be allowed...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88895</th>\n",
       "      <td>AAAUUP138190002317322139_OR.txt</td>\n",
       "      <td>We have to work to survive. Employers give us ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>rater_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88896</th>\n",
       "      <td>AAAUUP138190002408242136_OR.txt</td>\n",
       "      <td>Studies show that giving students holiday brea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rater_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88897</th>\n",
       "      <td>AAAUUP138190002420682110_OR.txt</td>\n",
       "      <td>Introduction:\\r\\n\\r\\nAuthor Ralph Waldo Emerso...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88898</th>\n",
       "      <td>AAAUUP138190002783782122_OR.txt</td>\n",
       "      <td>Technology, has been discuess by many knowledg...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rater_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88899</th>\n",
       "      <td>AAAUUP138190003078042110_OR.txt</td>\n",
       "      <td>Ralph Waldo, Emerson, wrote \"unless you try to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rater_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17744 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  \\\n",
       "71120                   2021000071.txt   \n",
       "71121                   2021000501.txt   \n",
       "71122                   2021000535.txt   \n",
       "71123                   2021000667.txt   \n",
       "71124                   2021000683.txt   \n",
       "...                                ...   \n",
       "88895  AAAUUP138190002317322139_OR.txt   \n",
       "88896  AAAUUP138190002408242136_OR.txt   \n",
       "88897  AAAUUP138190002420682110_OR.txt   \n",
       "88898  AAAUUP138190002783782122_OR.txt   \n",
       "88899  AAAUUP138190003078042110_OR.txt   \n",
       "\n",
       "                                                    text  labels     rater  \n",
       "71120  To the Principal,\\r\\n\\r\\nI think that policy 1...     4.0   rater_1  \n",
       "71121  Dear, TEACHER_NAME\\r\\n\\r\\nI think phone policy...     3.0   rater_1  \n",
       "71122  Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...     2.0   rater_1  \n",
       "71123  PHONES\\r\\n\\r\\nDear principal students should h...     3.0   rater_1  \n",
       "71124  phones\\r\\n\\r\\ni think phones should be allowed...     3.0   rater_1  \n",
       "...                                                  ...     ...       ...  \n",
       "88895  We have to work to survive. Employers give us ...     4.0  rater_23  \n",
       "88896  Studies show that giving students holiday brea...     5.0  rater_23  \n",
       "88897  Introduction:\\r\\n\\r\\nAuthor Ralph Waldo Emerso...     3.0  rater_23  \n",
       "88898  Technology, has been discuess by many knowledg...     2.0  rater_23  \n",
       "88899  Ralph Waldo, Emerson, wrote \"unless you try to...     3.0  rater_23  \n",
       "\n",
       "[17744 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df = df[df['labels']!=0]\n",
    "df['filename'].nunique()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b6594-2218-415e-8f28-5f131f84e284",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b78f922-f950-46a0-ab55-8c60d46764cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6690e1ab-d169-4cdf-9b6f-7602a04bdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a28961-6966-477d-9fd7-e3728d249c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"answerdotai/ModernBERT-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72d1d43-5f57-4412-9262-c142d8ca289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "def prepare_dataset_for_training(df_subset):\n",
    "    \"\"\"Prepare dataset for training\"\"\"\n",
    "    # Split data\n",
    "    train_df, eval_df = train_test_split(\n",
    "        df_subset, \n",
    "        test_size=0.2, \n",
    "        random_state=42,\n",
    "        stratify=df_subset['labels']\n",
    "    )\n",
    "    \n",
    "    # Create tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Convert to datasets\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    eval_dataset = Dataset.from_pandas(eval_df)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    return tokenized_train, tokenized_eval, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a57215-3500-48bb-be4c-0296a0160c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_regression(eval_pred):\n",
    "    \"\"\"Compute MSE for regression tasks\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Predictions are already continuous values\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(labels - predictions))  # Mean Absolute Error\n",
    "    \n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d20ec2-32ba-42de-a1bc-0d64e671d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on new data\n",
    "def predict_with_model(model, tokenizer, texts):\n",
    "    \"\"\"Make predictions on a list of texts\"\"\"\n",
    "    predictions = []\n",
    "    batch_size = 16\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        model.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # For regression, outputs.logits is already the predicted value\n",
    "            batch_preds = outputs.logits.flatten()\n",
    "            predictions.extend(batch_preds.cpu().numpy())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f9069ba-780b-4b24-80e0-4e6b04284fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = df['filename'].unique()\n",
    "def split_random_groups_numpy(filenames, num_groups=10):\n",
    "    \"\"\"\n",
    "    Split filenames into random groups using NumPy\n",
    "    \"\"\"\n",
    "    # Convert to numpy array and shuffle\n",
    "    arr = np.array(filenames)\n",
    "    np.random.shuffle(arr)\n",
    "    \n",
    "    # Split into groups\n",
    "    groups = np.array_split(arr, num_groups)\n",
    "    \n",
    "    # Convert back to lists\n",
    "    return [group.tolist() for group in groups]\n",
    "\n",
    "# Example usage\n",
    "test_groups = split_random_groups_numpy(filenames, 10)\n",
    "\n",
    "len(test_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74ac72b6-e96f-4e32-9e4f-715858f0d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 1/10\n",
      "============================================================\n",
      "Model 1:\n",
      "  Training files: 7989\n",
      "  Training samples: 15969\n",
      "  Test files: 888\n",
      "  Test samples: 1775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0593dd3b091e44c8a130d9d99098c335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9ed3b2acac4ada9563a5b14e7a70b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_94/1826919071.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3194' max='3194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3194/3194 18:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.425162</td>\n",
       "      <td>0.425162</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.733588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282300</td>\n",
       "      <td>0.417237</td>\n",
       "      <td>0.417237</td>\n",
       "      <td>0.645939</td>\n",
       "      <td>0.758949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy: 0.0000\n",
      "  Making predictions on held-out filenames...\n",
      "MSE on held-out test set: 0.3988018107395888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  10%|█         | 1/10 [20:14<3:02:09, 1214.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved model 1\n",
      "  Total predictions made: 1775\n",
      "\n",
      "============================================================\n",
      "Training Model 2/10\n",
      "============================================================\n",
      "Model 2:\n",
      "  Training files: 7989\n",
      "  Training samples: 15969\n",
      "  Test files: 888\n",
      "  Test samples: 1775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18427a4c67884cafb66d8d8c67a08af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a196f6d731ed4d699f92d347874afedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_94/1826919071.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3194' max='3194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3194/3194 16:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.414057</td>\n",
       "      <td>0.414057</td>\n",
       "      <td>0.643473</td>\n",
       "      <td>0.790447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.401080</td>\n",
       "      <td>0.401080</td>\n",
       "      <td>0.633309</td>\n",
       "      <td>0.777214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy: 0.0000\n",
      "  Making predictions on held-out filenames...\n",
      "MSE on held-out test set: 0.3996864132840256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  20%|██        | 2/10 [37:54<2:29:49, 1123.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved model 2\n",
      "  Total predictions made: 1775\n",
      "\n",
      "============================================================\n",
      "Training Model 3/10\n",
      "============================================================\n",
      "Model 3:\n",
      "  Training files: 7989\n",
      "  Training samples: 15968\n",
      "  Test files: 888\n",
      "  Test samples: 1776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616016491bee4faa9da25b6c2379db9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c710fe4ad57a4a1bb776871157b376f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_94/1826919071.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3194' max='3194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3194/3194 16:22, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.520843</td>\n",
       "      <td>0.520843</td>\n",
       "      <td>0.721694</td>\n",
       "      <td>0.742003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.672508</td>\n",
       "      <td>0.745216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy: 0.0000\n",
      "  Making predictions on held-out filenames...\n",
      "MSE on held-out test set: 0.4446254395019676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  30%|███       | 3/10 [55:27<2:07:20, 1091.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved model 3\n",
      "  Total predictions made: 1776\n",
      "\n",
      "============================================================\n",
      "Training Model 4/10\n",
      "============================================================\n",
      "Model 4:\n",
      "  Training files: 7989\n",
      "  Training samples: 15969\n",
      "  Test files: 888\n",
      "  Test samples: 1775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d21922fc50b4ddfa176e1894c34b7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729723e7e4f24805af56f875422639cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_94/1826919071.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2998' max='3194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2998/3194 14:47 < 00:58, 3.38 it/s, Epoch 1.88/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.475271</td>\n",
       "      <td>0.475271</td>\n",
       "      <td>0.689399</td>\n",
       "      <td>0.800733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy: 0.0000\n",
      "  Making predictions on held-out filenames...\n",
      "MSE on held-out test set: 0.3801430459730207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  40%|████      | 4/10 [1:13:04<1:47:47, 1077.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved model 4\n",
      "  Total predictions made: 1775\n",
      "\n",
      "============================================================\n",
      "Training Model 5/10\n",
      "============================================================\n",
      "Model 5:\n",
      "  Training files: 7989\n",
      "  Training samples: 15970\n",
      "  Test files: 888\n",
      "  Test samples: 1774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf86958a2824b9ab0653322ea8beb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f469f225df52487cb37d57cbb14e2305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_94/1826919071.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2701' max='3194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2701/3194 13:23 < 02:26, 3.36 it/s, Epoch 1.69/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.474543</td>\n",
       "      <td>0.474543</td>\n",
       "      <td>0.688871</td>\n",
       "      <td>0.776855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main training and prediction loop\n",
    "all_predictions_dfs = []\n",
    "mse_list = []\n",
    "\n",
    "for model_idx in tqdm(range(1, 11), desc=\"Training models\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model {model_idx}/10\")\n",
    "    print(f\"{'='*60}\")\n",
    "    test_filenames = test_groups[model_idx-1]\n",
    "    # Set seed for reproducibility (different for each model)\n",
    "    set_seed(model_idx * 42)\n",
    "    \n",
    "    # Create train and test splits\n",
    "    test_mask = df['filename'].isin(test_filenames)\n",
    "    train_mask = ~test_mask\n",
    "    \n",
    "    train_df = df[train_mask].copy()\n",
    "    test_df = df[test_mask].copy()\n",
    "    \n",
    "    print(f\"Model {model_idx}:\")\n",
    "    print(f\"  Training files: {len(filenames) - len(test_filenames)}\")\n",
    "    print(f\"  Training samples: {len(train_df)}\")\n",
    "    print(f\"  Test files: {len(test_filenames)}\")\n",
    "    print(f\"  Test samples: {len(test_df)}\")\n",
    "    \n",
    "    # Prepare training dataset\n",
    "    train_dataset, eval_dataset, tokenizer = prepare_dataset_for_training(train_df)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=1, \n",
    "    )\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./modernbert_model_{model_idx}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=1e-6,\n",
    "        learning_rate=8e-5,\n",
    "        logging_dir=f\"./logs_{model_idx}\",\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"mse\",\n",
    "        greater_is_better=False,\n",
    "        save_total_limit=1,\n",
    "        seed=model_idx * 42,\n",
    "        report_to=\"none\"  # Disable wandb/tensorboard if not needed\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics_regression,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(f\"  Validation Accuracy: {eval_result.get('eval_accuracy', 0):.4f}\")\n",
    "    \n",
    "    # Make predictions on held-out data\n",
    "    print(\"  Making predictions on held-out filenames...\")\n",
    "    \n",
    "    # Get texts from test set\n",
    "    test_texts = test_df['text'].tolist()\n",
    "    test_labels = test_df['labels'].tolist()\n",
    "    \n",
    "    # Predict\n",
    "    test_predictions = predict_with_model(model, tokenizer, test_texts)\n",
    "\n",
    "    print(f'MSE on held-out test set: {mean_squared_error(test_labels, test_predictions)}')\n",
    "    mse_list.append(mean_squared_error(test_labels, test_predictions))\n",
    "    # Create prediction dataframe\n",
    "    pred_df = test_df.copy()\n",
    "    pred_df['labels'] = test_predictions  # Replace actual labels with predictions\n",
    "    pred_df['rater'] = f'model_{model_idx}'\n",
    "    \n",
    "    # Combine train and test predictions for this model\n",
    "    all_pred_df = pred_df\n",
    "    \n",
    "    # Sort by filename to maintain order\n",
    "    all_pred_df = all_pred_df.sort_values('filename').reset_index(drop=True)\n",
    "    \n",
    "    # Add to list\n",
    "    all_predictions_dfs.append(all_pred_df)\n",
    "    \n",
    "    # Save model\n",
    "    model.save_pretrained(f\"./saved_model_{model_idx}\")\n",
    "    tokenizer.save_pretrained(f\"./saved_model_{model_idx}\")\n",
    "    \n",
    "    print(f\"  Saved model {model_idx}\")\n",
    "    print(f\"  Total predictions made: {len(all_pred_df)}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All models trained and predictions generated!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547a8c4-c87e-4f48-b5b2-067bc2c9c957",
   "metadata": {},
   "source": [
    "### Check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4af6a0c3-1b9f-48ee-a372-f9fed0d6e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3988018107395888, 0.3996864132840256, 0.4446254395019676, 0.3801430459730207, 0.4043201881015549, 0.38125827191194256, 0.40791846895121603, 0.4249178233803022, 0.41876848521325466, 0.4277511767301555]\n",
      "\n",
      "Final dataframe shape: (17744, 4)\n",
      "Number of unique filenames: 8877\n",
      "Number of raters: 10\n",
      "\n",
      "Sample of final predictions dataframe:\n",
      "          filename                                               text  \\\n",
      "0   2021000071.txt  To the Principal,\\r\\n\\r\\nI think that policy 1...   \n",
      "2   2021000501.txt  Dear, TEACHER_NAME\\r\\n\\r\\nI think phone policy...   \n",
      "4   2021000535.txt  Dear, Principal\\r\\n\\r\\nIn my opinion, I think ...   \n",
      "6   2021000667.txt  PHONES\\r\\n\\r\\nDear principal students should h...   \n",
      "8   2021000683.txt  phones\\r\\n\\r\\ni think phones should be allowed...   \n",
      "10  2021000705.txt  Do you really think students need cell phones ...   \n",
      "12  2021000748.txt  Should students be allowed to have cell phones...   \n",
      "14  2021000756.txt  dear TEACHER_NAME i think the you should let s...   \n",
      "16  2021001001.txt  Dear School Principal,\\r\\n\\r\\nI believe that s...   \n",
      "18  2021001035.txt  Policy1: I think we should be allowed to use o...   \n",
      "\n",
      "      labels     rater  \n",
      "0   3.418201   model_7  \n",
      "2   3.212650  model_10  \n",
      "4   3.386138   model_8  \n",
      "6   2.603854   model_8  \n",
      "8   2.903888   model_9  \n",
      "10  2.903831   model_1  \n",
      "12  3.160077   model_5  \n",
      "14  2.899178   model_9  \n",
      "16  3.498081   model_1  \n",
      "18  2.647101   model_8  \n"
     ]
    }
   ],
   "source": [
    "print(mse_list)\n",
    "\n",
    "# Combine all predictions into one dataframe\n",
    "final_df = pd.concat(all_predictions_dfs, ignore_index=True)\n",
    "\n",
    "# Sort by filename and rater for better organization\n",
    "final_df = final_df.sort_values(['filename', 'rater']).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.drop_duplicates().to_csv('../data/all_model_predictions1.csv', index=False)\n",
    "\n",
    "print(f\"\\nFinal dataframe shape: {final_df.shape}\")\n",
    "print(f\"Number of unique filenames: {final_df['filename'].nunique()}\")\n",
    "print(f\"Number of raters: {final_df['rater'].nunique()}\")\n",
    "\n",
    "# Display sample of the final dataframe\n",
    "print(\"\\nSample of final predictions dataframe:\")\n",
    "print(final_df.drop_duplicates().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e7e849-9336-4417-a77c-fdc0bc24f780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17744, 4)\n",
      "(8923, 4)\n"
     ]
    }
   ],
   "source": [
    "print(final_df.shape)\n",
    "print(final_df.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aed48295-abab-4411-b247-30e5331d7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates(subset=['filename', 'text', 'rater'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44cae74a-e923-4da4-8133-7edf6b6e96bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df['labels'] = final_df['labels'].round().astype(int)\n",
    "final_df.labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b070dd0-4084-4575-a99a-43d0b37caa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.concat([final_df, df])\n",
    "export_df.to_csv('../data/df_with_model_predictions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9b46fe-648d-4f68-8842-80c9b801ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4446254395019676\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mses = pd.Series([0.3988018107395888, 0.3996864132840256, 0.4446254395019676, 0.3801430459730207, 0.4043201881015549, 0.38125827191194256, 0.40791846895121603, 0.4249178233803022, 0.41876848521325466, 0.4277511767301555])\n",
    "\n",
    "print(mses.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wesenv]",
   "language": "python",
   "name": "conda-env-wesenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
